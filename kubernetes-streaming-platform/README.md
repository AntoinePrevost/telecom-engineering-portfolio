# Ginflix - Plateforme de Streaming Kubernetes
## Projet GIN207 - Applications et Services MultimÃ©dia

### Ã‰quipe
- **Antoine Prevost**
- **Jennifer Timani**

### Contexte AcadÃ©mique

Ce projet s'inscrit dans le cadre de l'UE **GIN207 : Applications et services multimÃ©dia** et constitue un mini-projet de 4 semaines intÃ©grant l'ensemble des compÃ©tences acquises dans la filiÃ¨re GIN (GIN201, 203, 204, 205, 207).

#### Objectifs PÃ©dagogiques
- Mise en Å“uvre d'un service de **VoD (VidÃ©o Ã  la Demande)** distribuÃ©
- DÃ©ploiement sur cluster **Kubernetes** multi-nodes
- IntÃ©gration des technologies vues : infrastructure cloud, rÃ©seau, sÃ©curitÃ©
- Analyse des architectures de diffusion multimÃ©dia modernes

---

## Documentation

### ğŸ“‹ Table des MatiÃ¨res
- **[Architecture Technique](docs/ARCHITECTURE.md)** - DÃ©tails complets de l'architecture microservices
- **[Guide de DÃ©ploiement](docs/DEPLOYMENT.md)** - Instructions d'installation et maintenance
- **Installation Rapide** - DÃ©marrage en une commande (ci-dessous)

---

## Vue d'ensemble

Plateforme de streaming vidÃ©o dÃ©ployÃ©e sur Kubernetes avec un cluster multi-nodes optimisÃ© pour les performances et la rÃ©silience. Le projet implÃ©mente une architecture de **Content Delivery Network (CDN)** distribuÃ©e avec autoscaling intelligent.

### Technologies UtilisÃ©es
- **Container Orchestration** : Kubernetes avec Kind
- **Load Balancing** : MetalLB (Layer 2)
- **Streaming Protocol** : HLS (HTTP Live Streaming)
- **Video Processing** : FFmpeg
- **Storage** : S3-compatible (Garage)
- **Database** : MongoDB
- **Security** : Network Policies, HTTPS/TLS

---

## Installation Rapide

### DÃ©ploiement AutomatisÃ©
```bash
# Installation complÃ¨te en une commande
./install.sh

# Monitoring temps rÃ©el
./monitor-scaling.sh
```

### AccÃ¨s aux Services
- **Frontend** : https://ginflix27.gin-telecom.ovh
- **Administration** : https://admin.ginflix27.gin-telecom.ovh

### Nettoyage
```bash
./clean.sh    # Suppression complÃ¨te
```

---

## Architecture Technique

### Configuration Multi-Nodes
Le cluster Kubernetes utilise **Kind** avec 3 nodes pour optimiser les performances et la rÃ©silience :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GINFLIX CLUSTER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Control-Plan (ginflix27-cluster-control-plane)             â”‚
â”‚ â”œâ”€â”€ Kubernetes API Server                                  â”‚
â”‚ â”œâ”€â”€ etcd                                                   â”‚
â”‚ â””â”€â”€ Scheduler + Controller Manager                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Worker-1 (ginflix27-cluster-worker)                        â”‚
â”‚ â”œâ”€â”€ Frontend Pods (2-4 replicas)                          â”‚
â”‚ â”œâ”€â”€ Backend Pods (2-8 replicas)                           â”‚
â”‚ â””â”€â”€ MongoDB Pod                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Worker-2 (ginflix27-cluster-worker2)                       â”‚
â”‚ â”œâ”€â”€ Streamer Pods (2-5 replicas)                          â”‚
â”‚ â”œâ”€â”€ Frontend-Admin Pods (2 replicas)                      â”‚
â”‚ â””â”€â”€ Load Distribution                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Network Policies SÃ©curisÃ©es
- **Principe** : Seul le Backend peut accÃ©der Ã  MongoDB
- **RÃ©sultat** : Protection contre les accÃ¨s non autorisÃ©s
- **RÃ¨gles** : Blocage de tout trafic sauf backend â†’ mongodb (port 27017)

## LoadBalancer avec MetalLB

### Configuration
- **Pool IP** : 172.18.255.200-250
- **Mode** : Layer 2 (ARP)
- **Attribution** : Automatique par service

### RÃ©solution problÃ¨me Kind
Les IPs MetalLB ne sont pas accessibles depuis l'hÃ´te par dÃ©faut. On ajoute une route statique pour rÃ©soudre ce problÃ¨me.

## Autoscaling (HPA)

### StratÃ©gie Agressive
Configuration d'un HPA ultra-agressif pour rÃ©pondre rapidement aux charges :
- **RÃ©action** : 15 secondes au lieu de 5 minutes standard
- **Scaling** : +3 pods ou doublement instantanÃ©
- **Justification** : Uploads FFmpeg = charge CPU intense mais temporaire

### Dimensionnement
| Service | CPU Request | Seuil HPA | Justification |
|---------|-------------|-----------|---------------|
| Backend | 200m | 40% | FFmpeg intensif |
| Frontend | 50m | 60% | Nginx lÃ©ger |
| Streamer | 100m | 50% | RÃ©seau modÃ©rÃ© |

## Metrics Server

### ProblÃ©matique Kind
Le metrics-server officiel ne fonctionne pas directement avec Kind Ã  cause des certificats TLS.

### Solution
J'ai automatisÃ© l'installation avec les patches nÃ©cessaires :
- Installation depuis le repository officiel
- Application automatique des arguments Kind
- Configuration TLS adaptÃ©e

---

## AmÃ©liorations ApportÃ©es

- âœ… Cluster multi-nodes pour la performance
- âœ… SÃ©curisation avec Network Policies
- âœ… LoadBalancer MetalLB fonctionnel
- âœ… Autoscaling ultra-rÃ©actif
- âœ… Installation automatisÃ©e complÃ¨te
- âœ… Monitoring en temps rÃ©el
- âœ… Configuration HTTPS
- âœ… Persistance des donnÃ©es MongoDB

---

## Support et Documentation

Pour plus d'informations dÃ©taillÃ©es :
- **Architecture complÃ¨te** : [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)
- **Guide de dÃ©ploiement** : [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)
- **Monitoring** : `./monitor-scaling.sh`
- **Troubleshooting** : Voir section dans le guide de dÃ©ploiement
